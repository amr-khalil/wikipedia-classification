{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse semi- und unstrukturierter Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2.1 | Wikipedia Scrapping\n",
    "\n",
    "(praktische Aufgabe, Abgabe Code – mit kurzer Beschreibung der „wie“ in den ersten\n",
    "Kommentarzeilen, Inputdaten, Beispielsession mit Output)\n",
    "Bauen Sie den Wikipedia-Artikel-Kategorisierer so aus, dass drei verschiedene Artikelklasse\n",
    "voneinander unterschieden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the txt files in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun May 31 09:35:53 2020\n",
    "\n",
    "@author: Amr.Khalil\n",
    "\"\"\"\n",
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# The website categories\n",
    "categories = {'Kunst & Kultur':0, 'Sport':1, 'Wissenschaft':2}\n",
    "\n",
    "# Create a dictionary for articles\n",
    "titles = dict()\n",
    "for category in categories.keys():\n",
    "    with open('train/'+category+'.txt','r') as f:\n",
    "        lis = f.read().split('\\n')\n",
    "        titles.update({category : [i.strip() for i in lis]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all articles in one dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kunst & Kultur : 100%|█████████████████████████████████████████████████████████████████| 73/73 [00:15<00:00,  4.79it/s]\n",
      "Sport          : 100%|███████████████████████████████████████████████████████████████| 103/103 [00:24<00:00,  4.24it/s]\n",
      "Wissenschaft   : 100%|█████████████████████████████████████████████████████████████████| 55/55 [00:12<00:00,  4.38it/s]\n"
     ]
    }
   ],
   "source": [
    "my_dict = dict()\n",
    "# Every category must have a list\n",
    "Kunst_und_Kultur = []\n",
    "Sport = []\n",
    "Wissenschaft = []\n",
    "\n",
    "for category in categories.keys(): # Loop on the 3 categories\n",
    "    for title in tqdm(titles[category], desc='{:<15}'.format(category)): # loop on the titels for every category\n",
    "        url = \"https://de.wikipedia.org/wiki/\"+title # Parse the wikipedia page\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        paragraphs = soup.select('p') # select all the paragraphs in the article\n",
    "        article_text = \"\"\n",
    "        for para in paragraphs:\n",
    "            article_text += para.text # Gather the paragraphs in one variable\n",
    "        \n",
    "        # Find the right category\n",
    "        if category == 'Kunst & Kultur': \n",
    "            Kunst_und_Kultur.append(article_text)\n",
    "            my_dict[category] = Kunst_und_Kultur\n",
    "        \n",
    "        elif category == 'Sport':\n",
    "            Sport.append(article_text)\n",
    "            my_dict[category] = Sport\n",
    "        \n",
    "        else:\n",
    "            Wissenschaft.append(article_text)\n",
    "            my_dict[category] = Wissenschaft\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Das Wort Kunst (lateinisch ars, griechisch téc...</td>\n",
       "      <td>Kunst &amp; Kultur</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Komposition (lateinisch compositio „Zusammenst...</td>\n",
       "      <td>Kunst &amp; Kultur</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Journalismus bezeichnet die periodische publiz...</td>\n",
       "      <td>Kunst &amp; Kultur</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Artikel verschwunden?\\n</td>\n",
       "      <td>Sport</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Als Radsport, schweizerisch auch Velosport, be...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Die Südostasienspiele sind sportliche Wettkämp...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Energie ist eine fundamentale physikalische Gr...</td>\n",
       "      <td>Wissenschaft</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Umwelt bezeichnet etwas, mit dem ein Lebewesen...</td>\n",
       "      <td>Wissenschaft</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Article        Category  \\\n",
       "0    Das Wort Kunst (lateinisch ars, griechisch téc...  Kunst & Kultur   \n",
       "30   Komposition (lateinisch compositio „Zusammenst...  Kunst & Kultur   \n",
       "60   Journalismus bezeichnet die periodische publiz...  Kunst & Kultur   \n",
       "90                             Artikel verschwunden?\\n           Sport   \n",
       "120  Als Radsport, schweizerisch auch Velosport, be...           Sport   \n",
       "150  Die Südostasienspiele sind sportliche Wettkämp...           Sport   \n",
       "180  Energie ist eine fundamentale physikalische Gr...    Wissenschaft   \n",
       "210  Umwelt bezeichnet etwas, mit dem ein Lebewesen...    Wissenschaft   \n",
       "\n",
       "     Category_ID  \n",
       "0              0  \n",
       "30             0  \n",
       "60             0  \n",
       "90             1  \n",
       "120            1  \n",
       "150            1  \n",
       "180            2  \n",
       "210            2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for the first category\n",
    "df1 = pd.DataFrame(my_dict['Kunst & Kultur'], columns =['Article'])\n",
    "df1['Category'] = \"Kunst & Kultur\"\n",
    "df1['Category_ID'] = 0\n",
    "\n",
    "# Create a DataFrame for the second category\n",
    "df2 = pd.DataFrame(my_dict['Sport'], columns =['Article'])\n",
    "df2['Category'] = \"Sport\"\n",
    "df2['Category_ID'] = 1\n",
    "\n",
    "# Create a DataFrame for the third category\n",
    "df3 = pd.DataFrame(my_dict['Wissenschaft'], columns =['Article'])\n",
    "df3['Category'] = \"Wissenschaft\"\n",
    "df3['Category_ID'] = 2\n",
    "\n",
    "# collect them in one DataFrame\n",
    "df = pd.concat([df1,df2,df3], ignore_index= True)\n",
    "df[::30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sport             103\n",
       "Kunst & Kultur     73\n",
       "Wissenschaft       55\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numer of the articles for each category\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "# We need this dataset in order to use the tokenizer\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Also download the list of stopwords to filter out\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.snowball import GermanStemmer\n",
    "stemmer = GermanStemmer()\n",
    "\n",
    "def process_text(text):\n",
    "    # Make all the strings lowercase and remove non alphabetic characters\n",
    "    text = re.sub('[^A-Za-zäöüß]', ' ', text.lower())\n",
    "\n",
    "    # Tokenize the text; this is, separate every sentence into a list of words\n",
    "    # Since the text is already split into sentences you don't have to call sent_tokenize\n",
    "    tokenized_text = word_tokenize(text)\n",
    "\n",
    "    # Remove the stopwords and stem each word to its root\n",
    "    stemm_text = [stemmer.stem(w) for w in tokenized_text if w not in stopwords.words('german')]\n",
    "    \n",
    "    #\n",
    "    clean_text = [w for w in stemm_text if len(w) > 2]\n",
    "\n",
    "    # This final output is a list of words\n",
    "    \n",
    "    return \" \".join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Data Processing on the DataFrame\n",
    "# It will take sometime\n",
    "df['Processed_Text'] = df['Article'].apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Data into CSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
